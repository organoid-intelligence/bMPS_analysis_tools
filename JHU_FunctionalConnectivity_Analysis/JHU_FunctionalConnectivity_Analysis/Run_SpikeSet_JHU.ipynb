{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4uE7Tg0rBD-"
   },
   "source": [
    "# Analysis of Organoid Data\n",
    "Look at maximum entropy models. Inspired by multiple papers, mainly [this](https://www.nature.com/articles/nature04701.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klsE7ROaxe1S"
   },
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9469,
     "status": "ok",
     "timestamp": 1685660351428,
     "user": {
      "displayName": "Jack Schenkman",
      "userId": "14281682336798665755"
     },
     "user_tz": 240
    },
    "id": "scYc_a87rQEF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import seaborn as sns \n",
    "import matplotlib as mpl\n",
    "\n",
    "#Import SpikeSet:\n",
    "from SpikeSet import spikeset_run_jhu as spikeset_run\n",
    "from SpikeSet import load_data_jhu as load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path='../Functional Connectivity/OrganoidResults/' #CHANGE PATHS HERE\n",
    "og_save_path='../CSVs/Organoids/'\n",
    "plot_scale=3 #Scale for plotting (default 1)\n",
    "dataset=2 #choose dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and save to CSVs/DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Manually change the folders to load the data due to the way data was shared\n",
    "\n",
    "#Hopkins Dataset 1\n",
    "if dataset == 1:\n",
    "    og_load_path='../HopkinsData/TimeCourseData/'\n",
    "    #CHANGE FOLDER NAME BELOW FOR EACH RUN\n",
    "    folder_name='Raw Data Week 5.5 to 8.5 (run 8 and LD)/'#'Raw Data Week 9.5 to 12.5 (run 6 and 7)/'#'Raw Data Week 5.5 to 8.5 (run 8 and LD)/'#'\n",
    "    #CHANGE RUN NAME AS NEEDED\n",
    "    run_name='Run8' #Run7,Run8,Run9\n",
    "    filenames=['div3','div5','div7','div9','div11','div13','div15','div17','div19','div21']\n",
    "    # # filename='div3' #change div name (div = days in vitro) \n",
    "    load_path_H5 =og_load_path+folder_name+run_name+'/'\n",
    "    save_path_CSV =og_save_path+folder_name+run_name+'/'\n",
    "    import os\n",
    "    if not os.path.exists(save_path_CSV):\n",
    "        os.makedirs(save_path_CSV)\n",
    "else:\n",
    "    #Hopkins Dataset 2\n",
    "    og_load_path='../HopkinsData2/'\n",
    "    #CHANGE FOLDER NAME BELOW FOR WELLS 4-6\n",
    "    folder_name='230601 RUN 8 Wells 1-3/'#230602 RUN 8 Wells 4-6/\n",
    "    #CHANGE SUBFOLDER NAMES AS NEEDED:\n",
    "    subfolder_names=['#1 (1-3 baseline)','#10 (well #3 post stim 1)','#11 (well #3 post stim 2)','#12 (well #3 post stim 3)',\n",
    "                     '#13 (well #3 post stim 4)','#14 (Well #1 180 minutes Well #2 120 minutes Well #3 60 minutes)',\n",
    "                     '#15 (Well #1 210 minutes Well #2 150 minutes Well #3 90 minutes)',\n",
    "                     '#16 (Well #1 240 minutes Well #2 180 minutes Well #3 120 minutes)',\n",
    "                     '#17 (Well #1 310 minutes Well #2 210 minutes Well #3 150 minutes)',\n",
    "                     '#18 (Well #1 340 minutes Well #2 240 minutes Well #3 180 minutes)',\n",
    "                     '#2 (well #1 post stim 1)','#3 (well #1 post stim 2)','#4 (well #1 post stim 3)','#5 (well #1 post stim 4)',\n",
    "                     '#6 (well #2 post stim 1)','#7 (well #2 post stim 2)','#8 (well #2 post stim 3)','#9 (well #2 post stim 4)']\n",
    "    # filename='div3' #change div name (div = days in vitro) \n",
    "    load_path_H5 =og_load_path+folder_name+'/'\n",
    "    save_path_CSV =og_save_path+folder_name+'/'\n",
    "    import os\n",
    "    if not os.path.exists(save_path_CSV):\n",
    "        os.makedirs(save_path_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save CSVs:\n",
    "if dataset == 1:\n",
    "    for filename in tqdm(filenames):\n",
    "        dfs=[]\n",
    "        dfs,df_keys,electrodes,f = load_data.load_h5_to_pd_jhu(load_path_H5+filename+'/data.raw.h5')#'/data.raw.h5') #M05898data, M05912data\n",
    "        i = 0\n",
    "        for file in dfs:\n",
    "            file=file.dropna()\n",
    "            file.to_csv(save_path+'_well'+str(i+1)+'.csv') #save each well to csv file\n",
    "            i+=1\n",
    "else:\n",
    "    for subfolder in tqdm(subfolder_names):\n",
    "        dfs=[]\n",
    "        dfs,df_keys,electrodes,f = load_data.load_h5_to_pd_jhu(load_path_H5+subfolder+'/data.raw.h5')#'/data.raw.h5') #M05898data, M05912data\n",
    "        i = 0\n",
    "        for file in dfs:\n",
    "            file=file.dropna()\n",
    "            file.to_csv(save_path+subfolder+'_well'+str(i+1)+'.csv') #save each well to csv file\n",
    "            i+=1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByemvHstPGIr"
   },
   "source": [
    "## Run Organoid Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hopkins Dataset 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### List of Parameters\n",
    "runs = [6]\n",
    "wells = [0,1,2, 3, 4, 5]\n",
    "divs = [3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n",
    "LDnames=['M05898','M05912']\n",
    "\n",
    "params = {}\n",
    "params[\"comment\"] = \"Add any information that you want\"\n",
    "params[\"sampling_freq\"] = 20000\n",
    "params[\"convolution_size\"] = int(0.1*params[\"sampling_freq\"])\n",
    "params[\"convolution_step\"] = int(0.05*params[\"sampling_freq\"])\n",
    "params[\"min_electrode_frequency\"] = 0\n",
    "params[\"permute_columns\"] = 0\n",
    "params[\"only_binary\"] = True\n",
    "params[\"seed\"] = 1\n",
    "results_path_default = save_path\n",
    "params[\"results_path\"] = save_path\n",
    "\n",
    "## Uncomment for Video:\n",
    "# video_params = {}\n",
    "# video_params[\"grouping_size\"] = 500\n",
    "# video_params[\"grouping_step\"] = 500\n",
    "# video_params[\"every_n\"] = 3\n",
    "# # video_params[\"num_edges\"] = 10000\n",
    "# video_params[\"exponential_coefficient\"] = 1 * 10 ** (-10)\n",
    "# video_params[\"use_exp\"] = False\n",
    "# video_params[\"normalize\"] = True\n",
    "# video_params[\"distance_metric\"] = \"mutual_information\"\n",
    "\n",
    "#Set up Results dict\n",
    "results = {}\n",
    "results[\"community_metric\"] = np.zeros((len(runs), len(wells), len(divs)))\n",
    "results[\"electrode_count\"] = np.zeros((len(runs), len(wells), len(divs)))\n",
    "results[\"shortest_path_length\"] = np.zeros((len(runs), len(wells), len(divs)))\n",
    "results[\"clustering_coeff\"] = np.zeros((len(runs), len(wells), len(divs)))\n",
    "results[\"dist_matrix\"] = {}\n",
    "\n",
    "if runs[0] == 9:\n",
    "    results[\"bct_vals\"] = [[[[{} for s in range(len(LDnames))] for i in range(len(divs))] for j in range(len(wells[3:]))] for k in range(len(runs))]\n",
    "    results[\"dist_matrix\"] = [[[[{} for s in range(len(LDnames))] for i in range(len(divs))] for j in range(len(wells[3:]))] for k in range(len(runs))]\n",
    "    pos = {}\n",
    "else:\n",
    "    results[\"bct_vals\"] = [[[{} for i in range(len(divs))] for j in range(len(wells))] for k in range(len(runs))]\n",
    "    results[\"dist_matrix\"] = [[[{} for i in range(len(divs))] for j in range(len(wells))] for k in range(len(runs))]\n",
    "\n",
    "    pos = {} #[for i in range(len(wells))] for j in\n",
    "    \n",
    "#Generate Full Electrode Array\n",
    "full_graph,pos=spikeset_run.generate_Electrode_Array(pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4026910,
     "status": "ok",
     "timestamp": 1685664440740,
     "user": {
      "displayName": "Jack Schenkman",
      "userId": "14281682336798665755"
     },
     "user_tz": 240
    },
    "id": "yCtunnhvkm6p",
    "outputId": "5c254a04-6fe7-4ddf-9d0f-5632769fb09d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run Dataset 1 graph analysis\n",
    "for run_index, run in enumerate(runs): #loop through Run folders\n",
    "    if run==6 or run == 7: \n",
    "        load_path = og_load_path+'/Raw Data Week 9.5 to 12.5 (run 6 and 7)/Run/' \n",
    "    else:\n",
    "        load_path =og_load_path+'/Raw Data Week 5.5 to 8.5 (run 8 and LD)/Run/' \n",
    "    \n",
    "    if run == 9: #Run 9 is separated into two distinct folders so we need to halve the wells tracker (vals)\n",
    "        vals = wells[3:]\n",
    "    else:\n",
    "        vals = wells\n",
    "    for well_index, well in tqdm(enumerate(vals)):  #Loop through wells using well tracker \n",
    "        print('\\n\\n WELL '+str(well)+'\\n\\n')\n",
    "        for div_index, div in enumerate(divs): #loop through days in vitro\n",
    "#             try:\n",
    "            if run == 9: \n",
    "                ldcount=0 \n",
    "                for LDname in LDnames: #loop through two folders for Run 9 only\n",
    "                    if LDname == 'M05912':\n",
    "                        path=  load_path + str(run) + \"/div\" + str(div) + \"well\" + str(well) + \"_M05912.csv\"\n",
    "                    elif LDname == 'M05898':\n",
    "                            path=  load_path + str(run) + \"/div\" + str(div) + \"well\" + str(well) + \"_M05898.csv\"\n",
    "                    params[\"run\"] = run\n",
    "                    params[\"results_path\"] = results_path_default + \"Run_\" + str(run) + \"/well_\" + str(well) + \"/\" + \"div_\" + str(div)+\"/\"+LDname\n",
    "                    results=spikeset_run.run_dataset1(run,run_index,well,well_index,div,div_index,path,ldcount,params,results,pos,full_graph)\n",
    "                    ldcount+=1\n",
    "            else: #All other runs don't need looping through\n",
    "                params[\"run\"] = run\n",
    "                params[\"results_path\"] = results_path_default + \"Run_\" + str(run) + \"/well_\" + str(well) + \"/\" + \"div_\" + str(div)+\"/\"\n",
    "                path=  load_path + str(run) + \"/div\" + str(div) + \"well\" + str(well) + \".csv\"\n",
    "                results=spikeset_run.run_dataset1(run,run_index,well,well_index,div,div_index,path,-1,params,results,pos,full_graph)\n",
    "                print(results[\"bct_vals\"][run_index][well_index][div_index][\"num_nodes\"])\n",
    "#             except:\n",
    "#                 print('error')\n",
    "#                 continue\n",
    "        ## Save Movie if wanted:\n",
    "          # spike_set.SpikeSet_ConnectivityMovie(video_params)\n",
    "\n",
    "\n",
    "# Save results dict as pickle:         \n",
    "import pickle\n",
    "with open(results_path_default+\"/\"+str(run)+\"_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hopkins Dataset 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### List of Parameters\n",
    "\n",
    "runs = [1,2]    \n",
    "wells = [0,1,2, 3, 4, 5]\n",
    "recording_num=list(range(18))\n",
    "\n",
    "params = {}\n",
    "params[\"comment\"] = \"Add any information that you want\"\n",
    "params[\"sampling_freq\"] = 20000\n",
    "params[\"convolution_size\"] = int(0.1*params[\"sampling_freq\"])\n",
    "params[\"convolution_step\"] = int(0.05*params[\"sampling_freq\"])\n",
    "params[\"min_electrode_frequency\"] = 0\n",
    "params[\"permute_columns\"] = 0\n",
    "params[\"only_binary\"] = True\n",
    "params[\"seed\"] = 1\n",
    "results_path_default = save_path\n",
    "params[\"results_path\"] = save_path\n",
    "\n",
    "## Uncomment for video\n",
    "# video_params = {}\n",
    "# video_params[\"grouping_size\"] = 500\n",
    "# video_params[\"grouping_step\"] = 500\n",
    "# video_params[\"every_n\"] = 3\n",
    "# video_params[\"num_edges\"] = 200\n",
    "# video_params[\"exponential_coefficient\"] = 1 * 10 ** (-10)\n",
    "# video_params[\"use_exp\"] = False\n",
    "# video_params[\"normalize\"] = True\n",
    "# video_params[\"distance_metric\"] = \"mutual_information\"\n",
    "#Set up Results dict\n",
    "\n",
    "\n",
    "\n",
    "results = {}\n",
    "results[\"dist_matrix\"] = {}\n",
    "\n",
    "#Set distance matrix data structure\n",
    "for run in runs:\n",
    "    results[\"dist_matrix\"][run-1] = {}\n",
    "    for well in wells:\n",
    "        results[\"dist_matrix\"][run-1][well] = {}\n",
    "        for recording in recording_num:\n",
    "            results[\"dist_matrix\"][run-1][well][recording] = {}\n",
    "\n",
    "results[\"bct_vals\"] = [[[{} for i in range(len(recording_num))] for j in range(len(wells))] for k in range(len(runs))]\n",
    "pos = {} \n",
    "\n",
    "#Generate Full Graph\n",
    "full_graph,pos=spikeset_run.generate_Electrode_Array(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run Dataset 2 graph analysis\n",
    "\n",
    "\n",
    "load_paths=[og_load_path+'/230601 RUN 8 Wells 1-3/',og_load_path+'/230602 RUN 8 Wells 4-6/']\n",
    "\n",
    "for run in runs:\n",
    "    if run == 0:\n",
    "        load_path=load_paths[0]\n",
    "    else:\n",
    "        load_path=load_paths[1]\n",
    "    for file in tqdm(os.listdir(load_path)):\n",
    "        recording_num1=int(file[1:3])\n",
    "        well_num=int(file.split(os.extsep)[0][-1:])\n",
    "        params[\"results_path\"] = results_path_default + \"Run_8\" + \"/well_\" + str(well_num) + \"_Data2/\" + \"folder_\"+str(run)+\"_recording_\" + str(recording_num1)+\"/\"\n",
    "        path=  load_path + file\n",
    "        results=spikeset_run.run_dataset2(run-1,well_num,well_num-1,recording_num1-1,load_path,path,params,results,pos,full_graph)\n",
    "\n",
    "      # spike_set.SpikeSet_ConnectivityMovie(video_params)\n",
    "\n",
    "\n",
    "# import pickle\n",
    "# with open(results_path_default+\"/\"+str(8)+\"_Dataset2_results.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(results,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IF YOU JUST WANT TO CHECK THE RAW DATA FOR CHANNELS, YOU CAN DO THAT  HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_paths=['../CSVs/Organoids/230601 RUN 8 Wells 1-3/','../CSVs/Organoids/230602 RUN 8 Wells 4-6/']\n",
    "# load_path=load_paths[0]\n",
    "# for file in tqdm(os.listdir(load_path)):\n",
    "#     recording_num1=int(file[1:3])\n",
    "#     well_num=int(file.split(os.extsep)[0][-1:])\n",
    "#     params[\"results_path\"] = results_path_default + \"Run_8\" + \"/well_\" + str(1) + \"_Data2/\" + \"folder_\"+str(1)+\"_recording_\" + str(1)+\"/\"\n",
    "#     path=  load_path + file\n",
    "#     data=pd.read_csv(path)\n",
    "#     data = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Theory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hopkins Dataset 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load saved pkl files\n",
    "\n",
    "runs=[8,9] #8 represents runs 6-8, 9 represents run 9\n",
    "results_path_default = '../Functional Connectivity/OrganoidResults/'\n",
    "for run in runs:\n",
    "    with open(results_path_default+\"/\"+str(run)+\"_results.pkl\", \"rb\") as f:\n",
    "        tmp = (pickle.load(f))\n",
    "        if run == 9:\n",
    "            bct_results9 = ((tmp['bct_vals'][0]))\n",
    "            results9     = ((tmp['dist_matrix']))\n",
    "        else:\n",
    "            bct_results  = ((tmp['bct_vals']))\n",
    "            results      = ((tmp['dist_matrix']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Highly innefficient way to combine results of all runs/wells/divs into one large array for each graph theory metric.\n",
    "This was done because of the way the data was provided. \n",
    "\"\"\"\n",
    "\n",
    "runs=[6,7,8,9]\n",
    "\n",
    "#wells,divs,ld\n",
    "vals       = wells[3:]\n",
    "num_nodes9 = np.zeros((len(vals),len(divs),len(LDnames)))\n",
    "num_edges9 = np.zeros((len(vals),len(divs),len(LDnames)))\n",
    "density9   = np.zeros((len(vals),len(divs),len(LDnames)))\n",
    "degree9    = np.zeros((len(vals),len(divs),len(LDnames)))\n",
    "q9         = np.zeros((len(vals),len(divs),len(LDnames)))\n",
    "pcoeff9    = [[[[] for s in range(len(LDnames))] for i in range(len(divs))] for j in range(len(vals))]\n",
    "mz9        = [[[[] for s in range(len(LDnames))] for i in range(len(divs))] for j in range(len(vals))]\n",
    "avg_spl9   = np.zeros((len(vals),len(divs),len(LDnames)))\n",
    "pos9       = [[[[] for s in range(len(LDnames))] for i in range(len(divs))] for j in range(len(vals))]\n",
    "weights9   = [[[[] for s in range(len(LDnames))] for i in range(len(divs))] for j in range(len(vals))]\n",
    " \n",
    "#wells,divs\n",
    "vals       = wells\n",
    "num_nodes  = np.zeros((len(runs),len(vals),len(divs)))\n",
    "num_edges  = np.zeros((len(runs),len(vals),len(divs)))\n",
    "density    = np.zeros((len(runs),len(vals),len(divs)))\n",
    "degree     = np.zeros((len(runs),len(vals),len(divs)))\n",
    "q          = np.zeros((len(runs),len(vals),len(divs)))\n",
    "pcoeff     = [[[[] for s in range(len(divs))] for i in range(len(vals))] for j in range(len(runs))]\n",
    "mz         = [[[[] for s in range(len(divs))] for i in range(len(vals))] for j in range(len(runs))]\n",
    "avg_spl    = np.zeros((len(runs),len(vals),len(divs)))\n",
    "pos8       = [[[[] for s in range(len(divs))] for i in range(len(vals))] for j in range(len(runs))]\n",
    "weights    = [[[[] for s in range(len(divs))] for i in range(len(vals))] for j in range(len(runs))]\n",
    "\n",
    "for run_index, run in tqdm(enumerate(runs)):\n",
    "    if run == 9:\n",
    "        vals = wells[3:]\n",
    "    else:\n",
    "        vals = wells\n",
    "    for well_index, well in tqdm(enumerate(vals)):    \n",
    "        for div_index, div in enumerate(divs):\n",
    "            if run == 9:\n",
    "                ldcount=0\n",
    "                for LDname in LDnames:\n",
    "                    if well == 5 and div ==17:\n",
    "                        num_nodes9[well_index,div_index,ldcount] = np.nan\n",
    "                        num_edges9[well_index,div_index,ldcount] = np.nan\n",
    "                        density9[well_index,div_index,ldcount]   = np.nan\n",
    "                        degree9[well_index,div_index,ldcount]    = np.nan\n",
    "                        q9[well_index,div_index,ldcount]         = np.nan\n",
    "                        pcoeff9[well_index][div_index][ldcount]  = [np.nan]*13209\n",
    "                        mz9[well_index][div_index][ldcount]      = [np.nan]*13209\n",
    "                        avg_spl9[well_index,div_index,ldcount]   = np.nan\n",
    "                        pos9[well_index][div_index][ldcount]     = [np.nan]*13209\n",
    "                        weights9[well_index][div_index][ldcount] = np.nan\n",
    "\n",
    "                    else:\n",
    "                        num_nodes9[well_index,div_index,ldcount] = bct_results9[well_index][div_index][ldcount]['num_nodes']\n",
    "                        num_edges9[well_index,div_index,ldcount] = bct_results9[well_index][div_index][ldcount]['num_edges']\n",
    "                        density9[well_index,div_index,ldcount]   = bct_results9[well_index][div_index][ldcount]['density']\n",
    "                        degree9[well_index,div_index,ldcount]    = bct_results9[well_index][div_index][ldcount]['degree'][0]\n",
    "                        q9[well_index,div_index,ldcount]         = bct_results9[well_index][div_index][ldcount]['community_metric']\n",
    "                        pcoeff9[well_index][div_index][ldcount]  = bct_results9[well_index][div_index][ldcount]['pcoeff']\n",
    "                        mz9[well_index][div_index][ldcount]      = bct_results9[well_index][div_index][ldcount]['mz']\n",
    "                        avg_spl9[well_index,div_index,ldcount]   = bct_results9[well_index][div_index][ldcount]['avg spl']\n",
    "                        pos9[well_index][div_index][ldcount]     = list(bct_results9[well_index][div_index][ldcount]['nw_pos'].values())\n",
    "                        weights9[well_index][div_index][ldcount] = results9[0][well_index][div_index][ldcount]\n",
    "\n",
    "                    ldcount+=1      \n",
    "            else:\n",
    "                num_nodes[run_index,well_index,div_index]        = bct_results[run_index][well_index][div_index]['num_nodes']\n",
    "                num_edges[run_index,well_index,div_index]        = bct_results[run_index][well_index][div_index]['num_edges']\n",
    "                density[run_index,well_index,div_index]          = bct_results[run_index][well_index][div_index]['density']\n",
    "                degree[run_index,well_index,div_index]           = bct_results[run_index][well_index][div_index]['degree'][0]\n",
    "                q[run_index,well_index,div_index]                = bct_results[run_index][well_index][div_index]['community_metric']\n",
    "                pcoeff[run_index][well_index][div_index]         = bct_results[run_index][well_index][div_index]['pcoeff']\n",
    "                mz[run_index][well_index][div_index]             = bct_results[run_index][well_index][div_index]['mz']\n",
    "                avg_spl[run_index,well_index,div_index]          = bct_results[run_index][well_index][div_index]['avg spl']\n",
    "                pos8[run_index][well_index][div_index]           = list(bct_results[run_index][well_index][div_index]['nw_pos'].values())\n",
    "                weights[run_index][well_index][div_index]        = results[run][well][div]\n",
    "\n",
    "if run == 9: #combine M0898 and M0912:\n",
    "    num_nodes9 = np.vstack((num_nodes9[:,:,0],(num_nodes9[:,:,1])))\n",
    "    num_edges9 = np.vstack((num_edges9[:,:,0],(num_edges9[:,:,1])))\n",
    "    density9   = np.vstack((density9[:,:,0],(density9[:,:,1])))\n",
    "    degree9    = np.vstack((degree9[:,:,0],(degree9[:,:,1])))\n",
    "    q9         = np.vstack((q9[:,:,0],(q9[:,:,1])))\n",
    "    avg_spl9   = np.vstack((avg_spl9[:,:,0],(avg_spl9[:,:,1])))\n",
    "\n",
    "    a=[];b1=[];a2=[];a3=[]\n",
    "    b=[];a1=[];b2=[];b3=[]\n",
    "    for i in range(len(pcoeff9)):\n",
    "        a.append(pd.DataFrame(pcoeff9[i]).values[:,0])\n",
    "        b.append(pd.DataFrame(pcoeff9[i]).values[:,1])\n",
    "        a1.append(pd.DataFrame(mz9[i]).values[:,0])\n",
    "        b1.append(pd.DataFrame(mz9[i]).values[:,1])\n",
    "        a2.append(pd.DataFrame(pos9[i]).values[:,0])\n",
    "        b2.append(pd.DataFrame(pos9[i]).values[:,1])\n",
    "        a3.append(pd.DataFrame(weights9[i]).values[:,0])\n",
    "        b3.append(pd.DataFrame(weights9[i]).values[:,1])\n",
    "    pcoeff9  = np.vstack((np.array(a), np.array(b)))\n",
    "    mz9      = np.vstack((np.array(a1), np.array(b1)))\n",
    "    pos9     = np.vstack((np.array(a2), np.array(b2)))\n",
    "    weights9 = np.vstack((np.array(a3), np.array(b3)))\n",
    "#Combine run 9 with others: \n",
    "#Check this\n",
    "num_nodes[-1]=num_nodes9\n",
    "num_edges[-1]=num_edges9\n",
    "density[-1]=density9\n",
    "degree[-1]=degree9\n",
    "q[-1]=q9\n",
    "avg_spl[-1]=avg_spl9\n",
    "for i in range(len(pcoeff9)):\n",
    "    for j in range(len(pcoeff9[i])):\n",
    "        pcoeff[-1][i][j]  = pcoeff9[i,j] #[run, well, div, nodes]\n",
    "        mz[-1][i][j]      = pcoeff9[i,j]\n",
    "        pos8[-1][i][j]    = pos9[i,j]\n",
    "        weights[-1][i][j] = weights9[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weird data type fixing: some data is saved in a strange data type with some graph theory toolboxes, so need to resave it as a float\n",
    "pcoeff_new = [None]*len(pcoeff9)\n",
    "mz_new     = [None]*len(mz9)\n",
    "for i in range(len(pcoeff9)):\n",
    "    \n",
    "    tmp  = np.vstack(pcoeff9[i][:]).astype(float)\n",
    "    tmp2 = np.vstack(mz9[i][:]).astype(float)\n",
    "\n",
    "    pcoeff_new[i] = tmp\n",
    "    mz_new[i]     = tmp2\n",
    "\n",
    "pcoeff_new = np.array(pcoeff_new)\n",
    "mz_new     = np.array(mz_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine weeks:\n",
    "num_nodes_week12 = np.mean(num_nodes[0:2],axis=0)\n",
    "num_nodes_week8  = np.nanmean((num_nodes[2],num_nodes9),axis=0)\n",
    "\n",
    "num_edges_week12 = np.mean(num_edges[0:2],axis=0)\n",
    "num_edges_week8  = np.nanmean((num_edges[2],num_edges9),axis=0)\n",
    "\n",
    "q_week12         = np.mean(q[0:2],axis=0)\n",
    "q_week8          = np.nanmean((q[2],q9),axis=0)\n",
    "\n",
    "avg_spl_week12   = np.mean(q[0:2],axis=0)\n",
    "avg_spl_week8    = np.nanmean((q[2],q9),axis=0)\n",
    "\n",
    "pcoeff_week12    = np.nanmean(pcoeff[0:2],axis=0)\n",
    "pcoeff_week8     = np.nanmean(np.stack((pcoeff_new,pcoeff[2])),axis=0)\n",
    "\n",
    "mz_week12        = np.nanmean(mz[0:2],axis=0)\n",
    "mz_week8         = np.nanmean(np.stack((mz_new,mz[2])),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Results Per DIV, across WELLS\n",
    "#ALL RUNS:\n",
    "\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "fig,ax=plt.subplots(1,3,figsize=(20,4))\n",
    "\n",
    "#Num Nodes\n",
    "b = ax[0].plot(np.nanmean(num_nodes_week8, axis=0), c='#03045e', label='Week 6-9')\n",
    "a = ax[0].plot(np.nanmean(num_nodes_week12, axis=0), c='#e63946', label='Week 10-13')\n",
    "\n",
    "ax[0].fill_between(range(len(np.nanmean(num_nodes_week12,axis=0))), np.nanmean(num_nodes_week12,axis=0)+np.nanstd(num_nodes_week12,axis=0), np.nanmean(num_nodes_week12,axis=0)-np.nanstd(num_nodes_week12,axis=0), alpha=0.2, color='#e63946')\n",
    "ax[0].fill_between(range(len(np.nanmean(num_nodes_week8,axis=0))), np.nanmean(num_nodes_week8,axis=0)+np.nanstd(num_nodes_week8,axis=0), np.nanmean(num_nodes_week8,axis=0)-np.nanstd(num_nodes_week8,axis=0), alpha=0.2, color='#03045e')\n",
    "\n",
    "ax[0].set_xticks(range(len(divs)))\n",
    "ax[0].set_xticklabels(divs)\n",
    "ax[0].set_xlabel('DOM')\n",
    "ax[0].set_ylabel('Avg Number of Nodes')\n",
    "ax[0].legend(title='Age of bMPS',ncols=2)#['Run 6','Run 7','Run 8','Run 9'])\n",
    "\n",
    "# #Num Edges\n",
    "a = ax[1].plot(np.nanmean(num_edges_week12, axis=0), c='#e63946', label='Week 10-13')\n",
    "b = ax[1].plot(np.nanmean(num_edges_week8, axis=0), c='#03045e', label='Week 6-9')\n",
    "\n",
    "ax[1].fill_between(range(len(np.nanmean(num_edges_week12,axis=0))),np.nanmean(num_edges_week12,axis=0)+np.nanstd(num_edges_week12,axis=0),np.nanmean(num_edges_week12,axis=0)-np.nanstd(num_edges_week12,axis=0),alpha=0.2,color='#e63946')\n",
    "ax[1].fill_between(range(len(np.nanmean(num_edges_week8,axis=0))),np.nanmean(num_edges_week8,axis=0)+np.nanstd(num_edges_week8,axis=0),np.nanmean(num_edges_week8,axis=0)-np.nanstd(num_edges_week8,axis=0),alpha=0.2,color='#03045e')\n",
    "\n",
    "ax[1].set_xticks(range(len(divs)))\n",
    "ax[1].set_xticklabels(divs)\n",
    "ax[1].set_xlabel('DOM')\n",
    "ax[1].set_ylabel('Avg Number of Edges')\n",
    "\n",
    "# #modularity\n",
    "a = ax[2].plot(np.nanmean(q_week12, axis=0), c='#e63946', label='Week 10-13')\n",
    "b = ax[2].plot(np.nanmean(q_week8, axis=0), c='#03045e', label='Week 6-9')\n",
    "\n",
    "ax[2].fill_between(range(len(np.nanmean(q_week12,axis=0))),np.nanmean(q_week12,axis=0)+np.nanstd(q_week12,axis=0),np.nanmean(q_week12,axis=0)-np.nanstd(q_week12,axis=0),alpha=0.2,color='#e63946')\n",
    "ax[2].fill_between(range(len(np.nanmean(q_week8,axis=0))),np.nanmean(q_week8,axis=0)+np.nanstd(q_week8,axis=0),np.nanmean(q_week8,axis=0)-np.nanstd(q_week8,axis=0),alpha=0.2,color='#03045e')\n",
    "\n",
    "ax[2].set_xticks(range(len(divs)))\n",
    "ax[2].set_xticklabels(divs)\n",
    "ax[2].set_xlabel('DOM')\n",
    "ax[2].set_ylabel('Modularity (q)')\n",
    "\n",
    "#Save PDF\n",
    "fig.savefig('../Functional Connectivity/OrganoidResults/AllRuns.pdf',format='pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Draw Pos + PCoeff/MZ graphs:\n",
    "labels=['Week 12','Week 8']\n",
    "nodes=np.array([i for i in full_graph.nodes])\n",
    "for i in tqdm(range(2)):\n",
    "    for j in range(len(pcoeff_week12)):\n",
    "        for k in range(len(pcoeff_week12[j])):\n",
    "            fig,axes=plt.subplots(1,2,figsize=(10,4))\n",
    "            ax=axes.flat\n",
    "            for x in range(len(ax)):\n",
    "                nx.draw(full_graph,pos,node_color='xkcd:pale orange',node_size=2,alpha=0.01,ax=ax[x])\n",
    "            if i == 0:\n",
    "                nx.draw(full_graph,pos,node_color=pcoeff_week12[j][k],cmap=plt.cm.Reds,node_size=5,ax=ax[0])\n",
    "                nx.draw(full_graph,pos,node_color=mz_week12[j][k],cmap=plt.cm.Blues,node_size=5,ax=ax[1])\n",
    "            else:\n",
    "                nx.draw(full_graph,pos,node_color=pcoeff_week8[j][k],cmap=plt.cm.Reds,node_size=5,ax=ax[0])\n",
    "                nx.draw(full_graph,pos,node_color=mz_week8[j][k],cmap=plt.cm.Blues,node_size=5,ax=ax[1])\n",
    "            plt.savefig(results_path_default+'Summary Results/pcoeff_mz_'+labels[i]+'_well '+str(wells[j])+'_div '+str(divs[k])+'.png',dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hopkins Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Repeat Graph theory Analysis but with the second dataset\n",
    "\"\"\"\n",
    "\n",
    "results_path_default = save_path\n",
    "\n",
    "with open(results_path_default+\"/8_Dataset2_results.pkl\", \"rb\") as f:\n",
    "    tmp=(pickle.load(f))\n",
    "    bct_results1=((tmp['bct_vals']))\n",
    "    results1=((tmp['dist_matrix']))\n",
    "\n",
    "bct_results=np.transpose(np.array(bct_results1),axes=[1,2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Only have 2 runs this time so it's easier to set up and loop through.\n",
    "runs = [1,2]    \n",
    "wells = [0,1,2, 3, 4, 5]\n",
    "recording_num=list(range(18))\n",
    "\n",
    "combined_bct_results = [[{} for i in range(len(recording_num)*2)] for j in range(len(wells))]\n",
    "combined_results = [[{} for i in range(len(recording_num)*2)] for j in range(len(wells))]\n",
    "\n",
    "runs = [1,2]\n",
    "for well_index, well in tqdm(enumerate(wells)):    \n",
    "    i=0\n",
    "    for recording in recording_num:\n",
    "        for run_index, run in enumerate(runs):\n",
    "            combined_bct_results[well_index][i]=bct_results[well_index][recording][run_index]\n",
    "            combined_results[well_index][i]=results1[run_index][well_index][recording]\n",
    "\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of relevant channels defined by Dowlette and Sam\n",
    "relevant_chans=[[195,320,422,372,674,110],\n",
    "               [426,205,239,108,429,462,526,467,247,484,534,146,329,129],\n",
    "               [424,193,463,9,181,102,159,294,378,235,435,272,75,25,436,317,107,275,471,211,400,303,440,19,404,469,146,99,363],\n",
    "               [659,73,834,981,704,687,466,455,451,301],\n",
    "               [537,548,656,716,179,975,502,961,363,499,685,590,822,586,651,806],\n",
    "               [147,184,603,789,360,249,569,948,258,862,8,734,759,435,247,439,419,573,105,815,289,285,50,916,206,969,984,397,571,979,157,450,380,531,415,658,765,517,961,92]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wells,divs\n",
    "vals               = wells\n",
    "num_nodes          = np.zeros((len(vals),len(recording_num)*2))\n",
    "num_edges          = np.zeros((len(vals),len(recording_num)*2))\n",
    "density            = np.zeros((len(vals),len(recording_num)*2))\n",
    "degree             = np.zeros((len(vals),len(recording_num)*2))\n",
    "q                  = np.zeros((len(vals),len(recording_num)*2))\n",
    "pcoeff             = [[[] for s in range(len(recording_num)*2)] for i in range(len(vals))]\n",
    "mz                 = [[[] for s in range(len(recording_num)*2)] for i in range(len(vals))]\n",
    "avg_spl            = np.zeros((len(vals),len(recording_num)*2))\n",
    "relevant_elecs_xy  = [[[] for s in range(len(recording_num)*2)] for i in range(len(vals))]\n",
    "relevant_elecs     = [[[] for s in range(len(recording_num)*2)] for i in range(len(vals))]\n",
    "relevant_elecs_pos = [[[] for s in range(len(recording_num)*2)] for i in range(len(vals))]\n",
    "relevant_adjMat    = [[[] for s in range(len(recording_num)*2)] for i in range(len(vals))]\n",
    "\n",
    "for well_index, well in tqdm(enumerate(vals)):    \n",
    "    for i in range(len(recording_num)*2):\n",
    "        num_nodes[well_index,i]          = combined_bct_results[well_index][i]['num_nodes']\n",
    "        num_edges[well_index,i]          = combined_bct_results[well_index][i]['num_edges']\n",
    "        density[well_index,i]            = combined_bct_results[well_index][i]['density']\n",
    "        degree[well_index,i]             = combined_bct_results[well_index][i]['degree'][0]\n",
    "        q[well_index,i]                  = combined_bct_results[well_index][i]['community_metric']\n",
    "        pcoeff[well_index][i]            = combined_bct_results[well_index][i]['pcoeff']\n",
    "        mz[well_index][i]                = combined_bct_results[well_index][i]['mz']\n",
    "        avg_spl[well_index,i]            = combined_bct_results[well_index][i]['avg spl']\n",
    "        chan_idx                         = np.where(np.in1d(combined_bct_results[well_index][i]['channel_ids'],relevant_chans[well_index]))[0]\n",
    "        relevant_elecs[well_index][i]    = chan_idx\n",
    "        relevant_elecs_xy[well_index][i] = np.array(list(combined_bct_results[well_index][i]['nw_pos'].values()))[chan_idx]\n",
    "        relevant_adjMat[well_index][i]   = combined_results[well_index][i][chan_idx,:][:,chan_idx]\n",
    "        #Relevant Pos\n",
    "        k = 0\n",
    "        a = {}\n",
    "        for j in relevant_elecs[well_index][i]:\n",
    "            a.update({k:tuple(relevant_elecs_xy[well_index][i][k])})\n",
    "            k+=1\n",
    "        relevant_elecs_pos[well_index][i] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot functional connectivity + PCoeff/MZ graphs:\n",
    "nodes = np.array([i for i in full_graph.nodes])\n",
    "for j in range(len(relevant_adjMat[0])):\n",
    "        fig = plt.figure()\n",
    "        ax  = plt.gca()\n",
    "        G   = nx.from_numpy_array(relevant_adjMat[0][j])\n",
    "        nx.draw(full_graph,pos,node_color='xkcd:pale orange',node_size=2,alpha=0.05,ax=ax)\n",
    "        nx.draw_networkx_nodes(G,relevant_elecs_pos[0][j],node_size=2,ax=ax)#,node_color=pcoeff[0][j],cmap=plt.cm.Reds,node_size=5,ax=ax[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results Per DIV, across WELLS\n",
    "#ALL RUNS:\n",
    "\n",
    "fig,ax = plt.subplots(1,3,figsize=(20,4))\n",
    "fig.suptitle('All Runs')\n",
    "#Degree\n",
    "colors = ['r','orange','yellow','g','cyan','b']\n",
    "for i in range(len(num_nodes)):\n",
    "    ax[0].plot(num_nodes[i,:],c=colors[i])\n",
    "\n",
    "ax[0].set_xticks(range(36))\n",
    "ax[0].set_xticklabels(range(1,37),rotation=45)\n",
    "ax[0].set_xlabel('Folder #')\n",
    "ax[0].set_ylabel('Avg Number of Nodes')\n",
    "ax[0].legend(['Well 1','Well 2','Well 3','Well 4','Well 5','Well 6'])\n",
    "\n",
    "#edges\n",
    "for i in range(len(num_edges)):\n",
    "    ax[1].plot(num_edges[i,:],c=colors[i])\n",
    "\n",
    "ax[1].set_xticks(range(36))\n",
    "ax[1].set_xticklabels(range(1,37),rotation=45)\n",
    "ax[1].set_xlabel('Folder #')\n",
    "ax[1].set_ylabel('Number of Edges')\n",
    "ax[1].legend(['Well 1','Well 2','Well 3','Well 4','Well 5','Well 6'])\n",
    "\n",
    "#modularity\n",
    "for i in range(len(q)):\n",
    "    ax[2].plot(q[i,:],c=colors[i])\n",
    "\n",
    "ax[2].set_xticks(range(36))\n",
    "ax[2].set_xticklabels(range(1,37),rotation=45)\n",
    "ax[2].set_xlabel('Folder #')\n",
    "ax[2].set_ylabel('Modularity')\n",
    "ax[2].legend(['Well 1','Well 2','Well 3','Well 4','Well 5','Well 6'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate into before, during, after stimulation:\n",
    "import copy\n",
    "\n",
    "wellNames = ['Well1','Well2','Well3','Well4','Well5','Well6']\n",
    "before = {'Number of Nodes':[np.nan]*len(recording_num),'Number of Edges':[np.nan]*len(recording_num),'Density':[np.nan]*len(recording_num),\n",
    "        'Degree':[np.nan]*len(recording_num),'Modularity':[np.nan]*len(recording_num),'Participation Coefficient':[np.nan]*len(recording_num),\n",
    "        'Module Z Score':[np.nan]*len(recording_num),'Shortest Path Length':[np.nan]*len(recording_num)}\n",
    "during = {'Number of Nodes':[np.nan]*len(recording_num),'Number of Edges':[np.nan]*len(recording_num),'Density':[np.nan]*len(recording_num),\n",
    "        'Degree':[np.nan]*len(recording_num),'Modularity':[np.nan]*len(recording_num),'Participation Coefficient':[np.nan]*len(recording_num),\n",
    "        'Module Z Score':[np.nan]*len(recording_num),'Shortest Path Length':[np.nan]*len(recording_num)}\n",
    "after  = {'Number of Nodes':[np.nan]*len(recording_num),'Number of Edges':[np.nan]*len(recording_num),'Density':[np.nan]*len(recording_num),\n",
    "        'Degree':[np.nan]*len(recording_num),'Modularity':[np.nan]*len(recording_num),'Participation Coefficient':[np.nan]*len(recording_num),\n",
    "        'Module Z Score':[np.nan]*len(recording_num),'Shortest Path Length':[np.nan]*len(recording_num)}\n",
    "\n",
    "wells  = {'Well1':{'before':copy.deepcopy(before),'during':copy.deepcopy(during),'after':copy.deepcopy(after)},\n",
    "       'Well2':{'before':copy.deepcopy(before),'during':copy.deepcopy(during),'after':copy.deepcopy(after)},       \n",
    "       'Well3':{'before':copy.deepcopy(before),'during':copy.deepcopy(during),'after':copy.deepcopy(after)},  \n",
    "       'Well4':{'before':copy.deepcopy(before),'during':copy.deepcopy(during),'after':copy.deepcopy(after)},       \n",
    "       'Well5':{'before':copy.deepcopy(before),'during':copy.deepcopy(during),'after':copy.deepcopy(after)},       \n",
    "       'Well6':{'before':copy.deepcopy(before),'during':copy.deepcopy(during),'after':copy.deepcopy(after)}}   \n",
    "j = 0\n",
    "for well in wells: #each well\n",
    "    for i in range(len(recording_num)): #each folder\n",
    "        if j < 3: \n",
    "            run_index = 0\n",
    "        else:\n",
    "            run_index = 1\n",
    "        if j == 0 or j == 3: #if well 1 or well 4\n",
    "            if i == 0: #if recording 1\n",
    "                wells[well]['before']['Number of Nodes'][i] = bct_results[j][i][run_index]['num_nodes']\n",
    "                wells[well]['before']['Number of Edges'][i] = bct_results[j][i][run_index]['num_edges']\n",
    "                wells[well]['before']['Modularity'][i]      = bct_results[j][i][run_index]['community_metric']\n",
    "            elif i >=1 and i <5: #if recording 2-5\n",
    "                wells[well]['during']['Number of Nodes'][i] = bct_results[j][i][run_index]['num_nodes']\n",
    "                wells[well]['during']['Number of Edges'][i] = bct_results[j][i][run_index]['num_edges']\n",
    "                wells[well]['during']['Modularity'][i]      = bct_results[j][i][run_index]['community_metric']\n",
    "\n",
    "            elif i >=5 and i <14: #if recording 6-14\n",
    "                wells[well]['after']['Number of Nodes'][i]  = bct_results[j][i][run_index]['num_nodes']\n",
    "                wells[well]['after']['Number of Edges'][i]  = bct_results[j][i][run_index]['num_edges']\n",
    "                wells[well]['after']['Modularity'][i]       = bct_results[j][i][run_index]['community_metric']\n",
    "\n",
    "        if j == 1 or j == 4: #if well 2 or well 5\n",
    "            if i == 4:\n",
    "                wells[well]['before']['Number of Nodes'][i] = bct_results[j][i][run_index]['num_nodes']\n",
    "                wells[well]['before']['Number of Edges'][i] = bct_results[j][i][run_index]['num_edges']\n",
    "                wells[well]['before']['Modularity'][i]      = bct_results[j][i][run_index]['community_metric']\n",
    "            elif i >=5 and i <9:\n",
    "                wells[well]['during']['Number of Nodes'][i] = bct_results[j][i][run_index]['num_nodes']\n",
    "                wells[well]['during']['Number of Edges'][i] = bct_results[j][i][run_index]['num_edges']\n",
    "                wells[well]['during']['Modularity'][i]      = bct_results[j][i][run_index]['community_metric']\n",
    "\n",
    "            elif i >=9 and i < 16:\n",
    "                wells[well]['after']['Number of Nodes'][i]  = bct_results[j][i][run_index]['num_nodes']\n",
    "                wells[well]['after']['Number of Edges'][i]  = bct_results[j][i][run_index]['num_edges']\n",
    "                wells[well]['after']['Modularity'][i]       = bct_results[j][i][run_index]['community_metric']\n",
    "\n",
    "        if j == 2 or j == 5: #if well 3 or well 6\n",
    "            if i == 8:\n",
    "                wells[well]['before']['Number of Nodes'][i]  = bct_results[j][i][run_index]['num_nodes']\n",
    "                wells[well]['before']['Number of Edges'][i]  = bct_results[j][i][run_index]['num_edges']\n",
    "                wells[well]['before']['Modularity'][i]       = bct_results[j][i][run_index]['community_metric']\n",
    "\n",
    "            elif i >= 8 and i <13:\n",
    "                wells[well]['during']['Number of Nodes'][i]  = bct_results[j][i][run_index]['num_nodes']\n",
    "                wells[well]['during']['Number of Edges'][i]  = bct_results[j][i][run_index]['num_edges']\n",
    "                wells[well]['during']['Modularity'][i]       = bct_results[j][i][run_index]['community_metric']\n",
    "\n",
    "            elif i >= 13 and i <18:\n",
    "                wells[well]['after']['Number of Nodes'][i]   = bct_results[j][i][run_index]['num_nodes']\n",
    "                wells[well]['after']['Number of Edges'][i]   = bct_results[j][i][run_index]['num_edges']\n",
    "                wells[well]['after']['Modularity'][i]        = bct_results[j][i][run_index]['community_metric']\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise Before, During, After \n",
    "\n",
    "#Results Per DIV, across WELLS\n",
    "#ALL RUNS:\n",
    "\n",
    "fig, ax   = plt.subplots(1,3,figsize=(20,5))\n",
    "#Degree\n",
    "num_nodes = [[None]*3 for i in range(len(wells))]\n",
    "i=0\n",
    "for well in wells:\n",
    "    num_nodes[i][0] = np.nanmean(wells[well]['before']['Number of Nodes'])\n",
    "    num_nodes[i][1] = np.nanmean(wells[well]['during']['Number of Nodes'])\n",
    "    num_nodes[i][2] = np.nanmean(wells[well]['after']['Number of Nodes'])\n",
    "    i+=1\n",
    "ax[0].hist(np.array(num_nodes).T)\n",
    "ax[0].set_xticks([0,1,2])\n",
    "ax[0].set_xticklabels(['before','during','after'],rotation=45)\n",
    "ax[0].set_ylabel('Number of Nodes')\n",
    "\n",
    "# #edges\n",
    "num_edges = [[None]*3 for i in range(len(wells))]\n",
    "i = 0\n",
    "for well in wells:\n",
    "    num_edges[i][0] = np.nanmean(wells[well]['before']['Number of Edges'])\n",
    "    num_edges[i][1] = np.nanmean(wells[well]['during']['Number of Edges'])\n",
    "    num_edges[i][2] = np.nanmean(wells[well]['after']['Number of Edges'])\n",
    "    i+=1\n",
    "ax[1].plot(np.array(num_edges).T,'-o')\n",
    "ax[1].set_xticks([0,1,2])\n",
    "ax[1].set_xticklabels(['before','during','after'],rotation=45)\n",
    "ax[1].set_ylabel('Number of Edges')\n",
    "\n",
    "# #modularity\n",
    "q = [[None]*3 for i in range(len(wells))]\n",
    "i = 0\n",
    "for well in wells:\n",
    "    q[i][0] = np.nanmean(wells[well]['before']['Modularity'])\n",
    "    q[i][1] = np.nanmean(wells[well]['during']['Modularity'])\n",
    "    q[i][2] = np.nanmean(wells[well]['after']['Modularity'])\n",
    "    i+=1\n",
    "ax[2].plot(np.array(q).T,'-o')\n",
    "ax[2].set_xticks([0,1,2])\n",
    "ax[2].set_xticklabels(['before','during','after'],rotation=45)\n",
    "ax[2].set_ylabel('Modularity (q)')\n",
    "ax[2].legend(['Well 1','Well 2','Well 3','Well 4','Well 5','Well 6'])\n",
    "\n",
    "fig.savefig('../Functional Connectivity/OrganoidResults/AllRuns.pdf',format='pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the values of num_nodes\n",
    "num_nodes_values = np.array(num_nodes)\n",
    "num_nodes        = pd.DataFrame({'before':num_nodes_values[:,0],'during':num_nodes_values[:,1],'after':num_nodes_values[:,2]})\n",
    "\n",
    "num_edges_values = np.array(num_edges)\n",
    "num_edges        = pd.DataFrame({'before':num_edges_values[:,0],'during':num_edges_values[:,1],'after':num_edges_values[:,2]})\n",
    "\n",
    "q_values         = np.array(q)\n",
    "q                = pd.DataFrame({'before':q_values[:,0],'during':q_values[:,1],'after':q_values[:,2]})\n",
    "\n",
    "vals             = [num_nodes,num_edges,q]\n",
    "labels           = ['Num Nodes','Num Edges','Modularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplots:\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set(font_scale=1.4)\n",
    "\n",
    "# Define custom color palette\n",
    "custom_palette = sns.color_palette(\"Set2\")\n",
    "# Swap colors for 'during' and 'after'\n",
    "custom_palette[1], custom_palette[2] = custom_palette[2], custom_palette[1]\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(15, 5.5))\n",
    "fig.tight_layout(pad=3)\n",
    "for i,val in enumerate(vals):\n",
    "    ax = axes.flat[i]\n",
    "    sns.boxplot(data = val, palette = custom_palette, width = 0.4, showfliers = False, showmeans=True, \n",
    "                meanprops = {\"markerfacecolor\": \"black\", \n",
    "                            \"markeredgecolor\": \"black\",\n",
    "                            \"markersize\": \"5\"}, dodge=False, ax=ax)\n",
    "    ax.legend([], [], frameon=False)\n",
    "\n",
    "    # Set plot title and labels\n",
    "    plt.title('Data Frame')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('Y-axis')\n",
    "\n",
    "    # Bold x and y tick labels\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontweight='bold')\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontweight='bold')\n",
    "    \n",
    "    ax.set_ylabel(labels[i], fontsize=18)\n",
    "    ax.set_xlabel('Recording Phase', fontsize=18)\n",
    "    ax.grid(False)\n",
    "    sns.set(rc={'figure.figsize':(5,4)})\n",
    "\n",
    "    dfm_mean = val.mean()\n",
    "    sns.lineplot(data=dfm_mean, marker='o', ax=ax, legend=False,color = 'r')\n",
    "\n",
    "    # Format y-axis ticks with scaled notation\n",
    "    yticks = ax.get_yticks()\n",
    "    if max(yticks) > 10000:\n",
    "        formatter = ScalarFormatter(useMathText=True)\n",
    "        formatter.set_scientific(True)\n",
    "        formatter.set_powerlimits((-1,1))  # Adjust the power limits as needed\n",
    "        ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "fig.savefig('../OrganoidResults/AllRuns2.pdf',format='pdf',dpi=300)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
